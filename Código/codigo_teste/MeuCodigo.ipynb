{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificador do codificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo: escolas-dez-2010.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolas-dez-2011.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolas-dez-2012.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolas-dez-2013.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolas-dez-2014.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolas-dez-2015.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolas122018.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolas122019.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolas122020.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolas122021.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolas122022.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolas122023.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolasr34.csv | Codificação detectada: utf-8\n",
      "Arquivo: escolasr34dez2017.csv | Codificação detectada: utf-8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chardet\n",
    "import pandas as pd\n",
    "\n",
    "caminho_diretorio = 'G:/0_Estudos_Analise_de_Dados/07_Projeto/DADOS_PROJETO/Data/Data/Escolas'\n",
    "lista_dfs = []\n",
    "\n",
    "for arquivo in os.listdir(caminho_diretorio):\n",
    "    if arquivo.endswith('.csv'):\n",
    "        caminho_completo = os.path.join(caminho_diretorio, arquivo)\n",
    "\n",
    "        # Detecta a codificação do arquivo\n",
    "        with open(caminho_completo, 'rb') as f:\n",
    "            result = chardet.detect(f.read(10000))  # Lê uma amostra do arquivo\n",
    "            encoding_detectado = result['encoding']\n",
    "            print(f\"Arquivo: {arquivo} | Codificação detectada: {encoding_detectado}\")\n",
    "\n",
    "        # Lê o arquivo com a codificação correta\n",
    "        df = pd.read_csv(caminho_completo, sep=\";\", encoding=encoding_detectado, low_memory=False)\n",
    "        lista_dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padronizados para utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convertendo escolas-dez-2010.csv de utf-8 para UTF-8\n",
      "Convertendo escolas-dez-2011.csv de utf-8 para UTF-8\n",
      "Convertendo escolas-dez-2012.csv de utf-8 para UTF-8\n",
      "Convertendo escolas-dez-2013.csv de utf-8 para UTF-8\n",
      "Convertendo escolas-dez-2014.csv de utf-8 para UTF-8\n",
      "Convertendo escolas-dez-2015.csv de utf-8 para UTF-8\n",
      "Convertendo escolas122018.csv de utf-8 para UTF-8\n",
      "Convertendo escolas122019.csv de utf-8 para UTF-8\n",
      "Convertendo escolas122020.csv de utf-8 para UTF-8\n",
      "Convertendo escolas122021.csv de utf-8 para UTF-8\n",
      "Convertendo escolas122022.csv de utf-8 para UTF-8\n",
      "Convertendo escolas122023.csv de utf-8 para UTF-8\n",
      "Convertendo escolasr34.csv de utf-8 para UTF-8\n",
      "Convertendo escolasr34dez2017.csv de utf-8 para UTF-8\n",
      "Todos os arquivos foram convertidos para UTF-8!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chardet\n",
    "\n",
    "caminho_diretorio = 'G:/0_Estudos_Analise_de_Dados/07_Projeto/DADOS_PROJETO/Data/Data/Escolas'\n",
    "\n",
    "for arquivo in os.listdir(caminho_diretorio):\n",
    "    if arquivo.endswith('.csv'):\n",
    "        caminho_completo = os.path.join(caminho_diretorio, arquivo)\n",
    "\n",
    "        # Detecta a codificação\n",
    "        with open(caminho_completo, 'rb') as f:\n",
    "            result = chardet.detect(f.read(10000))\n",
    "            encoding_detectado = result['encoding']\n",
    "            print(f\"Convertendo {arquivo} de {encoding_detectado} para UTF-8\")\n",
    "\n",
    "        if encoding_detectado is None:\n",
    "            encoding_detectado = 'ISO-8859-1'\n",
    "\n",
    "        # Lê o arquivo na codificação detectada e reescreve em UTF-8\n",
    "        with open(caminho_completo, 'r', encoding=encoding_detectado, errors='replace') as f:\n",
    "            conteudo = f.read()\n",
    "\n",
    "        with open(caminho_completo, 'w', encoding='utf-8') as f:\n",
    "            f.write(conteudo)\n",
    "\n",
    "print(\"Todos os arquivos foram convertidos para UTF-8!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando em lista com df\n",
    "\n",
    "#Caminho da pasta com os dados que seram transformados em df\n",
    "caminho_diretorio = 'G:/0_Estudos_Analise_de_Dados/07_Projeto/DADOS_PROJETO/Data/Data/Escolas' \n",
    "\n",
    "lista_dfs= []\n",
    "\n",
    "for arquivo in  os.listdir(caminho_diretorio):\n",
    "    if arquivo.endswith('.csv'):\n",
    "        caminho_completo = caminho_diretorio + '/' + arquivo\n",
    "        df = pd.read_csv(caminho_completo, sep=\";\", encoding='utf-8',  ) \n",
    "        lista_dfs.append(df)\n",
    "    else:\n",
    "        continue    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padronizando as colunas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n",
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n",
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n",
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n",
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n",
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n",
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n",
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n",
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n",
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n",
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n",
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n",
      "Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!\n"
     ]
    }
   ],
   "source": [
    "colunas_padrao = [\n",
    "    \"DRE\", \"CODESC\", \"TIPOESC\", \"NOMESC\", \"NOMESCOFI\", \"CEU\", \"DIRETORIA\", \"SUBPREF\",\n",
    "    \"ENDERECO\", \"NUMERO\", \"BAIRRO\", \"CEP\", \"TEL1\", \"TEL2\", \"FAX\", \"SITUACAO\", \"CODDIST\",\n",
    "    \"DISTRITO\", \"SETOR\", \"CODINEP\", \"CD_CIE\", \"EH\", \"FX_ETARIA\", \"DT_CRIACAO\", \"ATO_CRIACAO\",\n",
    "    \"DOM_CRIACAO\", \"DT_INI_CONV\", \"DT_AUTORIZA\", \"DT_EXTINCAO\", \"NOME_ANT\", \"REDE\",\n",
    "    \"LATITUDE\", \"LONGITUDE\", \"DATABASE\"\n",
    "]\n",
    "colunas_para_dropar = [\n",
    "    'T2D3D', 'T2D3D15', 'T2D3D14', 'T2D3D13', 'T2D3D12', 'T2D3D11', 'T2D3D10', 'T2D3D09', 'T2D3D08', 'T2D3D07',\n",
    "    'DTURNOS', 'DTURNOS15', 'DTURNOS14', 'DTURNOS13', 'DTURNOS12', 'DTURNOS11', 'DTURNOS10', 'DTURNOS09', 'DTURNOS08', 'DTURNOS07',\n",
    "    'T2D3D16', 'DTURNOS16'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for df in lista_dfs:\n",
    "    df.columns = df.columns.str.upper()  # Converte os nomes das colunas para maiúsculas\n",
    "    try:\n",
    "        #Usa set().intersection() para encontrar apenas colunas que existem no DataFrame\n",
    "        colunas_para_remover = list(set(colunas_para_dropar).intersection(df.columns))\n",
    "        if colunas_para_dropar:\n",
    "            df.drop(columns=colunas_para_dropar, inplace=True)\n",
    "    except:\n",
    "        print('Colunas não encontradas, já podem ter sido excluidas em uma execução anterior!')\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DRE', 'CODESC', 'TIPOESC', 'NOMESC', 'CEU', 'DIRETORIA', 'SUBPREF',\n",
       "       'ENDERECO', 'NUMERO', 'BAIRRO', 'CEP', 'TEL1', 'TEL2', 'FAX',\n",
       "       'SITUACAO', 'CODDIST', 'DISTRITO', 'SETOR', 'CODINEP', 'CD_CIE', 'EH',\n",
       "       'FX_ETARIA', 'DT_CRIACAO', 'ATO_CRIACAO', 'DOM_CRIACAO', 'DT_INI_CONV',\n",
       "       'DT_INI_FUNC', 'DT_AUTORIZA', 'DT_EXTINTAO', 'NOME_ANT', 'REDE',\n",
       "       'LATITUDE', 'LONGITUDE', 'DATABASE'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(lista_dfs[7].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4761 entries, 0 to 4760\n",
      "Data columns (total 34 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   dre          4761 non-null   object \n",
      " 1   codesc       4761 non-null   int64  \n",
      " 2   tipoesc      4761 non-null   object \n",
      " 3   nomesc       4761 non-null   object \n",
      " 4   nomescofi    4761 non-null   object \n",
      " 5   CEU          152 non-null    object \n",
      " 6   diretoria    4761 non-null   object \n",
      " 7   subpref      4761 non-null   object \n",
      " 8   ENDERECO     4761 non-null   object \n",
      " 9   NUMERO       4761 non-null   object \n",
      " 10  BAIRRO       4761 non-null   object \n",
      " 11  CEP          4761 non-null   int64  \n",
      " 12  TEL1         4652 non-null   object \n",
      " 13  TEL2         1312 non-null   object \n",
      " 14  FAX          531 non-null    object \n",
      " 15  SITUACAO     4761 non-null   object \n",
      " 16  coddist      4761 non-null   int64  \n",
      " 17  distrito     4761 non-null   object \n",
      " 18  setor        4761 non-null   int64  \n",
      " 19  codinep      4448 non-null   float64\n",
      " 20  cd_cie       4448 non-null   float64\n",
      " 21  eh           1602 non-null   object \n",
      " 22  FX_ETARIA    1852 non-null   object \n",
      " 23  DT_CRIACAO   3879 non-null   object \n",
      " 24  ATO_CRIACAO  3879 non-null   object \n",
      " 25  DOM_CRIACAO  3876 non-null   object \n",
      " 26  DT_INI_CONV  1477 non-null   object \n",
      " 27  DT_AUTORIZA  3153 non-null   object \n",
      " 28  dt_extincao  0 non-null      float64\n",
      " 29  NOME_ANT     1770 non-null   object \n",
      " 30  REDE         4761 non-null   object \n",
      " 31  LATITUDE     4761 non-null   int64  \n",
      " 32  LONGITUDE    4761 non-null   int64  \n",
      " 33  DATABASE     4761 non-null   object \n",
      "dtypes: float64(3), int64(6), object(25)\n",
      "memory usage: 1.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(lista_dfs[8].info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto_etl_escola",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
